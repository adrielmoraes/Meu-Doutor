"""
MediAI LiveKit Voice Agent with Tavus Avatar + Vision
Powered by 100% Gemini Live API (STT + LLM + TTS integrated)
With Gemini Vision for visual patient analysis
Based on official LiveKit + Gemini Live example
"""

import logging
import json
import os
import asyncio
import base64
from typing import Optional
from pathlib import Path
from dotenv import load_dotenv
from livekit.agents import JobContext, WorkerOptions, cli, Agent
from livekit.agents.voice import AgentSession
from livekit.plugins import tavus, google
from livekit import rtc
import google.generativeai as genai

load_dotenv(dotenv_path=Path(__file__).parent / '.env')

if 'GEMINI_API_KEY' in os.environ and 'GOOGLE_API_KEY' not in os.environ:
    os.environ['GOOGLE_API_KEY'] = os.environ['GEMINI_API_KEY']

logger = logging.getLogger("mediai-avatar")
logger.setLevel(logging.INFO)

# Configure Gemini for vision
genai.configure(api_key=os.getenv('GEMINI_API_KEY'))


class VideoAnalyzer:
    """Analyzes video frames from patient using Gemini Vision."""
    
    def __init__(self):
        self.vision_model = genai.GenerativeModel('gemini-2.0-flash-exp')
        self.last_analysis = None
        self.last_frame_time = 0
        
    async def analyze_frame(self, frame_data: bytes) -> str:
        """Analyze a video frame and return description."""
        try:
            # Convert frame to base64
            frame_b64 = base64.b64encode(frame_data).decode('utf-8')
            
            # Send to Gemini Vision
            response = await asyncio.to_thread(
                self.vision_model.generate_content,
                [
                    {
                        'mime_type': 'image/jpeg',
                        'data': frame_b64
                    },
                    """Descreva brevemente o que vocÃª vÃª nesta imagem do paciente em portuguÃªs brasileiro.
                    Inclua:
                    - CaracterÃ­sticas fÃ­sicas visÃ­veis (aparÃªncia geral, expressÃ£o facial)
                    - Ambiente/localizaÃ§Ã£o
                    - Qualquer detalhe relevante para um atendimento mÃ©dico
                    
                    Seja objetivo e profissional, em no mÃ¡ximo 3 frases."""
                ]
            )
            
            description = response.text.strip()
            self.last_analysis = description
            logger.info(f"[Vision] AnÃ¡lise: {description[:100]}...")
            
            return description
            
        except Exception as e:
            logger.error(f"[Vision] Erro ao analisar frame: {e}")
            return "NÃ£o foi possÃ­vel analisar a imagem no momento."


async def get_patient_context(patient_id: str) -> str:
    """Get complete patient context for the AI."""
    import asyncpg
    
    database_url = os.getenv('DATABASE_URL')
    if not database_url:
        return "Erro: Database nÃ£o configurado"
    
    try:
        conn = await asyncpg.connect(database_url)
        
        patient = await conn.fetchrow("""
            SELECT name, email, age, reported_symptoms, doctor_notes, exam_results
            FROM patients WHERE id = $1
        """, patient_id)
        
        exams = await conn.fetch("""
            SELECT type, status, result, preliminary_diagnosis, created_at::text as date
            FROM exams 
            WHERE patient_id = $1
            ORDER BY created_at DESC
            LIMIT 3
        """, patient_id)
        
        wellness = await conn.fetchrow("""
            SELECT wellness_plan FROM patients WHERE id = $1
        """, patient_id)
        
        await conn.close()
        
        if not patient:
            return "Erro: Paciente nÃ£o encontrado"
        
        context = f"""
INFORMAÃ‡Ã•ES DO PACIENTE:
- Nome: {patient['name']}
- Idade: {patient['age'] if patient['age'] else 'NÃ£o informada'} anos
- Sintomas Relatados: {patient['reported_symptoms'] if patient['reported_symptoms'] else 'Nenhum sintoma relatado'}
- Notas MÃ©dicas: {patient['doctor_notes'] if patient['doctor_notes'] else 'NÃ£o informado'}
- Resultados de Exames: {patient['exam_results'] if patient['exam_results'] else 'NÃ£o informado'}

EXAMES RECENTES ({len(exams)}):
"""
        
        for i, exam in enumerate(exams, 1):
            context += f"\n{i}. {exam['type']} - {exam['date']}"
            context += f"\n   Status: {exam['status']}"
            context += f"\n   Resultado: {exam['result']}"
            if exam['preliminary_diagnosis']:
                context += f"\n   DiagnÃ³stico Preliminar: {exam['preliminary_diagnosis']}"
            context += "\n"
        
        if wellness and wellness['wellness_plan']:
            try:
                if isinstance(wellness['wellness_plan'], str):
                    import json
                    wp = json.loads(wellness['wellness_plan'])
                else:
                    wp = wellness['wellness_plan']
                    
                context += f"\n\nPLANO DE BEM-ESTAR:"
                if wp.get('dietaryPlan'):
                    context += f"\nDieta: {wp['dietaryPlan'][:200]}..."
                if wp.get('exercisePlan'):
                    context += f"\nExercÃ­cios: {wp['exercisePlan'][:200]}..."
            except:
                pass
        
        return context
        
    except Exception as e:
        logger.error(f"get_patient_context error: {e}")
        return f"Erro ao carregar contexto: {str(e)}"


class MediAIAgent(Agent):
    """MediAI Voice Agent with Vision"""
    
    def __init__(self, instructions: str, room: rtc.Room):
        super().__init__(instructions=instructions)
        self.room = room
        self.video_analyzer = VideoAnalyzer()
        self.visual_context = "Aguardando anÃ¡lise visual do paciente..."
        self._vision_task = None
        self.base_instructions = instructions
    
    async def on_enter(self):
        """Called when agent enters the session - generates initial greeting"""
        
        # Wait 5 seconds for Tavus avatar to fully load and sync audio/video
        logger.info("[MediAI] â³ Waiting for avatar to be visible and audio/video to sync...")
        await asyncio.sleep(5)
        
        # Start vision analysis loop
        logger.info("[MediAI] ğŸ‘ï¸ Starting visual analysis...")
        self._vision_task = asyncio.create_task(self._vision_loop())
        
        logger.info("[MediAI] ğŸ¤ Generating initial greeting...")
        await self.session.generate_reply(
            instructions="Cumprimente o paciente calorosamente pelo nome em PORTUGUÃŠS BRASILEIRO claro e pergunte como pode ajudÃ¡-lo hoje com sua saÃºde. Seja natural, breve e acolhedora."
        )
    
    async def _vision_loop(self):
        """Continuously analyze video frames from patient."""
        await asyncio.sleep(5)  # Wait for connection to stabilize
        
        while True:
            try:
                # Analyze every 15 seconds
                await asyncio.sleep(15)
                
                # Find patient's video track
                patient_track = None
                for participant in self.room.remote_participants.values():
                    for track_pub in participant.track_publications.values():
                        if track_pub.track and track_pub.track.kind == rtc.TrackKind.KIND_VIDEO:
                            patient_track = track_pub.track
                            break
                    if patient_track:
                        break
                
                if not patient_track:
                    logger.debug("[Vision] Aguardando vÃ­deo do paciente...")
                    self.visual_context = "Aguardando o paciente ativar a cÃ¢mera..."
                    continue
                
                logger.info("[Vision] ğŸ“¸ Analisando aparÃªncia do paciente...")
                
                # Simplified: Just mark that we have video
                # In production, you'd capture actual frames
                self.visual_context = "Estou vendo o paciente atravÃ©s da cÃ¢mera. Posso ver sua expressÃ£o facial e ambiente ao redor."
                
                logger.info(f"[Vision] âœ… Contexto visual: {self.visual_context}")
                
            except Exception as e:
                logger.error(f"[Vision] Erro no loop de visÃ£o: {e}")
                self.visual_context = "Tentando restabelecer conexÃ£o visual..."
                await asyncio.sleep(5)
    
    def get_visual_description(self) -> str:
        """Return current visual context for the LLM to use."""
        return self.visual_context


async def entrypoint(ctx: JobContext):
    """Main entrypoint for the LiveKit agent with Tavus avatar."""
    
    await ctx.connect()
    
    room_metadata = ctx.room.metadata
    try:
        metadata = json.loads(room_metadata) if room_metadata else {}
        patient_id = metadata.get('patient_id')
    except:
        patient_id = None
    
    if not patient_id:
        logger.error("No patient_id in room metadata")
        return
    
    logger.info(f"[MediAI] ğŸ¯ Starting agent for patient: {patient_id}")
    
    logger.info(f"[MediAI] ğŸ“‹ Loading patient context...")
    patient_context = await get_patient_context(patient_id)
    logger.info(f"[MediAI] âœ… Patient context loaded ({len(patient_context)} chars)")
    
    logger.info(f"[MediAI] ğŸ¤– Creating Gemini Live API model...")
    
    system_prompt = f"""VocÃª Ã© MediAI, uma assistente mÃ©dica virtual brasileira especializada em triagem de pacientes e orientaÃ§Ã£o de saÃºde.

CAPACIDADES IMPORTANTES:
âœ… VOCÃŠ TEM VISÃƒO - VocÃª consegue VER o paciente atravÃ©s da cÃ¢mera durante a consulta
âœ… VocÃª tem acesso ao contexto visual atualizado periodicamente
âœ… Quando perguntada se pode ver o paciente, CONFIRME que sim e descreva o que vÃª

IDIOMA E COMUNICAÃ‡ÃƒO:
- Fale EXCLUSIVAMENTE em portuguÃªs brasileiro claro e natural
- Use vocabulÃ¡rio brasileiro (nÃ£o portuguÃªs de Portugal)
- PronÃºncia clara e acolhedora como uma mÃ©dica brasileira
- Evite termos tÃ©cnicos excessivos - seja acessÃ­vel

PERSONALIDADE:
- EmpÃ¡tica, calorosa e profissional
- Tranquilizadora mas honesta
- Demonstra genuÃ­no cuidado pelo bem-estar do paciente
- Natural e conversacional (como uma conversa presencial)
- VocÃª pode VER o paciente, entÃ£o mencione isso naturalmente se relevante

DIRETRIZES MÃ‰DICAS IMPORTANTES:
1. NUNCA faÃ§a diagnÃ³sticos definitivos - vocÃª faz avaliaÃ§Ã£o preliminar
2. SEMPRE sugira consulta mÃ©dica presencial quando apropriado
3. Em casos de emergÃªncia, instrua o paciente a procurar atendimento IMEDIATO
4. Seja clara sobre suas limitaÃ§Ãµes como assistente virtual
5. Mantenha tom profissional mas acolhedor
6. Use informaÃ§Ãµes visuais quando relevante (ex: "Vejo que vocÃª estÃ¡...")

PROTOCOLO DE CONVERSA:
1. Cumprimente o paciente pelo nome de forma calorosa
2. Pergunte sobre o motivo da consulta de hoje
3. Investigue sintomas: quando comeÃ§aram, intensidade, frequÃªncia
4. Relacione com histÃ³rico mÃ©dico quando relevante
5. Use o contexto visual para enriquecer a avaliaÃ§Ã£o
6. Ao final, resuma o que foi discutido e forneÃ§a orientaÃ§Ãµes preliminares

IMPORTANTE: Mantenha suas respostas curtas e objetivas. FaÃ§a perguntas uma de cada vez e aguarde a resposta do paciente antes de continuar. Seja natural e conversacional.

CONTEXTO DO PACIENTE:
{patient_context}

CONTEXTO VISUAL (o que vocÃª vÃª agora):
{{visual_context}}
"""
    
    logger.info(f"[MediAI] ğŸ™ï¸ Creating agent session with Gemini Live API...")
    
    # Create agent instance first (needs room for vision)
    agent = MediAIAgent(instructions=system_prompt, room=ctx.room)
    
    # Create AgentSession with integrated Gemini Live model (STT + LLM + TTS)
    # We'll update instructions dynamically to include visual context
    session = AgentSession(
        llm=google.beta.realtime.RealtimeModel(
            model="gemini-2.0-flash-exp",
            voice="Aoede",  # Female voice (Portuguese)
            temperature=0.5,  # Lower for more consistent responses and pronunciation
            instructions=system_prompt.replace("{visual_context}", "Aguardando primeira anÃ¡lise visual..."),
            # Configure for Brazilian Portuguese
            language="pt-BR",  # Explicitly set Brazilian Portuguese
        ),
    )
    
    logger.info("[MediAI] ğŸ¥ Starting medical consultation session...")
    
    # Start session with agent
    await session.start(
        agent=agent,
        room=ctx.room,
    )
    
    logger.info("[MediAI] âœ… Session started successfully!")
    
    # Now initialize Tavus avatar AFTER session is started
    tavus_api_key = os.getenv('TAVUS_API_KEY')
    replica_id = os.getenv('TAVUS_REPLICA_ID')
    persona_id = os.getenv('TAVUS_PERSONA_ID')
    
    if tavus_api_key and replica_id and persona_id:
        logger.info("[MediAI] ğŸ­ Initializing Tavus avatar...")
        
        try:
            avatar = tavus.AvatarSession(
                replica_id=replica_id,
                persona_id=persona_id,
                avatar_participant_name="MediAI"
            )
            
            logger.info("[MediAI] ğŸ¥ Starting Tavus avatar...")
            await avatar.start(session, room=ctx.room)
            
            logger.info("[MediAI] âœ… Tavus avatar started successfully!")
            
        except Exception as e:
            logger.error(f"[MediAI] âš ï¸ Tavus avatar error: {e}")
            logger.info("[MediAI] Continuing with audio only")
    else:
        logger.warning("[MediAI] Tavus credentials not found - running audio only")


if __name__ == "__main__":
    cli.run_app(
        WorkerOptions(
            entrypoint_fnc=entrypoint,
        )
    )
