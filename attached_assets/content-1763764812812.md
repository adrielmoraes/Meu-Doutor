[Skip to main content](https://docs.livekit.io/agents/models/realtime/plugins/gemini/#main-content)

[Docs](https://docs.livekit.io/home/)

[GitHub](https://github.com/livekit/livekit) [Slack](https://livekit.io/join-slack)

Search`` `K`

[Sign in with Cloud](https://cloud.livekit.io/login?r=/login_success?redirect_to=https://docs.livekit.io/agents/models/realtime/plugins/gemini/)

[Home](https://docs.livekit.io/home/) [AI Agents](https://docs.livekit.io/agents/) [Telephony](https://docs.livekit.io/sip/) [Recipes](https://docs.livekit.io/recipes/) [Reference](https://docs.livekit.io/reference/)

![](https://docs.livekit.io/images/icons/icon-logo-gemini.svg)

On this page

[Overview](https://docs.livekit.io/agents/models/realtime/plugins/gemini/#overview) [Quick reference](https://docs.livekit.io/agents/models/realtime/plugins/gemini/#quick-reference) [Installation](https://docs.livekit.io/agents/models/realtime/plugins/gemini/#installation) [Authentication](https://docs.livekit.io/agents/models/realtime/plugins/gemini/#authentication) [Usage](https://docs.livekit.io/agents/models/realtime/plugins/gemini/#usage) [Parameters](https://docs.livekit.io/agents/models/realtime/plugins/gemini/#parameters) [Gemini tools](https://docs.livekit.io/agents/models/realtime/plugins/gemini/#gemini-tools) [Turn detection](https://docs.livekit.io/agents/models/realtime/plugins/gemini/#turn-detection) [Thinking](https://docs.livekit.io/agents/models/realtime/plugins/gemini/#thinking) [Usage with separate TTS](https://docs.livekit.io/agents/models/realtime/plugins/gemini/#separate-tts) [Additional resources](https://docs.livekit.io/agents/models/realtime/plugins/gemini/#additional-resources)

Copy pageSee more page options

Available in

Python

\|

Node.js

[Try the playground\\
\\
Chat with a voice assistant built with LiveKit and the Gemini Live API\\
\\
![Try the playground](https://docs.livekit.io/_next/image/?url=%2Fimages%2Fagents%2Fgemini-playground-thumb.png&w=640&q=75)](https://gemini.livekit.io/)

## Overview

Google's [Gemini Live API](https://ai.google.dev/gemini-api/docs/live) enables low-latency, two-way interactions that use text, audio, and video input, with audio and text output. LiveKit's Google plugin includes a `RealtimeModel` class that allows you to use this API to create agents with natural, human-like voice conversations.

## Quick reference

This section includes a basic usage example and some reference material. For links to more detailed documentation, see [Additional resources](https://docs.livekit.io/agents/models/realtime/plugins/gemini/#additional-resources).

### Installation

Install the Google plugin:

PythonNode.js

```shell
uv add "livekit-agents[google]~=1.2"
```

```shell
pnpm add "@livekit/agents-plugin-google@1.x"
```

### Authentication

The Google plugin requires authentication based on your chosen service:

- For Vertex AI, you must set the `GOOGLE_APPLICATION_CREDENTIALS` environment variable to the path of the service account key file. For more information about mounting files as secrets when deploying to LiveKit Cloud, see [File-mounted secrets](https://docs.livekit.io/agents/ops/deployment/secrets/#file-mounted-secrets) .
- For the Google Gemini API, set the `GOOGLE_API_KEY` environment variable.

### Usage

Use the Gemini Live API within an `AgentSession`. For example, you can use it in the [Voice AI quickstart](https://docs.livekit.io/agents/start/voice-ai/).

PythonNode.js

```python
from livekit.plugins import google

session = AgentSession(
    llm=google.realtime.RealtimeModel(
        model="gemini-2.0-flash-exp",
        voice="Puck",
        temperature=0.8,
        instructions="You are a helpful assistant",
    ),
)
```

```typescript
import * as google from '@livekit/agents-plugin-google';

const session = new voice.AgentSession({
   llm: new google.realtime.RealtimeModel({
      model: "gemini-2.5-flash-native-audio-preview-09-2025",
      voice: "Puck",
      temperature: 0.8,
      instructions: "You are a helpful assistant",
   }),
});
```

### Parameters

This section describes some of the available parameters. For a complete reference of all available parameters, see theplugin reference links in the [Additional resources](https://docs.livekit.io/agents/models/realtime/plugins/gemini/#additional-resources) section.

**instructions**`string``Optional`

[#](https://docs.livekit.io/agents/models/realtime/plugins/gemini/#instructions)

System instructions to better control the model's output and specify tone and sentiment of responses. To learn more,see [System instructions](https://ai.google.dev/gemini-api/docs/live#system-instructions).

**model**`LiveAPIModels | string``Required`Default:`gemini-2.0-flash-exp`

[#](https://docs.livekit.io/agents/models/realtime/plugins/gemini/#model)

Live API model to use.

**api\_key**`string``Required`Env:`GOOGLE_API_KEY`

[#](https://docs.livekit.io/agents/models/realtime/plugins/gemini/#api_key)

Google Gemini API key.

**voice**`Voice | string``Required`Default:`Puck`

[#](https://docs.livekit.io/agents/models/realtime/plugins/gemini/#voice)

Name of the Gemini Live API voice. For a full list, see [Voices](https://ai.google.dev/gemini-api/docs/live#change-voices).

**modalities**`list[Modality]``Optional`Default:`["AUDIO"]`

[#](https://docs.livekit.io/agents/models/realtime/plugins/gemini/#modalities)

List of response modalities to use. Set to `["TEXT"]` to use the model in text-only mode with a [separate TTS plugin](https://docs.livekit.io/agents/models/realtime/plugins/gemini/#separate-tts).

**vertexai**`boolean``Required`Default:`false`

[#](https://docs.livekit.io/agents/models/realtime/plugins/gemini/#vertexai)

If set to true, use Vertex AI.

**project**`string``Optional`Env:`GOOGLE_CLOUD_PROJECT`

[#](https://docs.livekit.io/agents/models/realtime/plugins/gemini/#project)

Google Cloud project ID to use for the API (if `vertextai=True`). By default, it uses the project in the serviceaccount key file (set using the `GOOGLE_APPLICATION_CREDENTIALS` environment variable).

**location**`string``Optional`Env:`GOOGLE_CLOUD_LOCATION`

[#](https://docs.livekit.io/agents/models/realtime/plugins/gemini/#location)

Google Cloud location to use for the API (if `vertextai=True`). By default, it uses the location from the serviceaccount key file or `us-central1`.

**thinking\_config**`ThinkingConfig``Optional`

[#](https://docs.livekit.io/agents/models/realtime/plugins/gemini/#thinking_config)

Configuration for the model's thinking mode, if supported. For more information, see [Thinking](https://docs.livekit.io/agents/models/realtime/plugins/gemini/#thinking).

**enable\_affective\_dialog**`boolean``Optional`Default:`false`

[#](https://docs.livekit.io/agents/models/realtime/plugins/gemini/#enable_affective_dialog)

Enable affective dialog on supported native audio models. For more information, see [Affective dialog](https://ai.google.dev/gemini-api/docs/live-guide#affective-dialog).

**proactivity**`boolean``Optional`Default:`false`

[#](https://docs.livekit.io/agents/models/realtime/plugins/gemini/#proactivity)

Enable proactive audio, where the model can decide not to respond to certain inputs. Requires a native audio model. For more information, see [Proactive audio](https://ai.google.dev/gemini-api/docs/live-guide#proactive-audio).

**\_gemini\_tools**`list[GeminiTool]``Optional`

[#](https://docs.livekit.io/agents/models/realtime/plugins/gemini/#_gemini_tools)

List of built-in Google tools, such as Google Search. For more information, see [Gemini tools](https://docs.livekit.io/agents/models/realtime/plugins/gemini/#gemini-tools).

### Gemini tools

**Experimental feature**

This integration is experimental and may change in a future SDK release.

The `_gemini_tools` parameter allows you to use built-in Google tools with the Gemini model. For example, you can use this feature to implement [Grounding with Google Search](https://ai.google.dev/gemini-api/docs/live-tools#google-search):

PythonNode.js

```python
from google.genai import types

session = AgentSession(
    llm=google.realtime.RealtimeModel(
        model="gemini-2.5-flash-native-audio-preview-09-2025",
        _gemini_tools=[types.GoogleSearch()],
    )
)
```

```typescript
import * as google from '@livekit/agents-plugin-google';

const session = new voice.AgentSession({
   llm: new google.realtime.RealtimeModel({
      model: "gemini-2.0-flash-exp",
      geminiTools: [new google.types.GoogleSearch()],
   }),
});
```

## Turn detection

The Gemini Live API includes built-in VAD-based turn detection, enabled by default. To use LiveKit's turn detection model instead, configure the model to disable automatic activity detection. A separate streaming STT model is required in order to use LiveKit's turn detection model.

PythonNode.js

```python
from google.genai import types
from livekit.agents import AgentSession
from livekit.plugins.turn_detector.multilingual import MultilingualModel

session = AgentSession(
   turn_detection=MultilingualModel(),
   llm=google.realtime.RealtimeModel(
      realtime_input_config=types.RealtimeInputConfig(
      automatic_activity_detection=types.AutomaticActivityDetection(
         disabled=True,
      ),
   ),
   input_audio_transcription=None,
   stt="assemblyai/universal-streaming",
)
```

```typescript
import * as google from '@livekit/agents-plugin-google';
import * as livekit from '@livekit/agents-plugin-livekit';

const session = new voice.AgentSession({
   turnDetection: new MultilingualModel(),
   llm: new google.realtime.RealtimeModel({
      model: "gemini-2.0-flash-exp",
      realtimeInputConfig: {
         automaticActivityDetection: {
            disabled: true,
         },
      },
   }),
   stt: "assemblyai/universal-streaming",
   turnDetection: new livekit.turnDetector.MultilingualModel(),
});
```

## Thinking

The latest model, `gemini-2.5-flash-native-audio-preview-09-2025`, supports thinking. You can configure its behavior with the `thinking_config` parameter.

By default, the model's thoughts are forwarded like other transcripts. To disable this, set `include_thoughts=False`:

```python
from google.genai import types

# ...

session = AgentSession(
    llm=google.realtime.RealtimeModel(
        thinking_config=types.ThinkingConfig(
            include_thoughts=False,
        ),
    ),
)
```

For other available parameters, such as `thinking_budget`, see the [Gemini thinking docs](https://ai.google.dev/gemini-api/docs/thinking).

## Usage with separate TTS

To use the Gemini Live API with a different [TTS instance](https://docs.livekit.io/agents/models/tts/), configure it with a text-only response modality and include a TTS instance in your `AgentSession` configuration. This configuration allows you to gain the benefits of realtime speech comprehension while maintaining complete control over the speech output.

PythonNode.js

```python
from google.genai.types import Modality

session = AgentSession(
    llm=google.realtime.RealtimeModel(modalities=[Modality.TEXT]),
    tts="cartesia/sonic-3",
)
```

```typescript
import * as google from '@livekit/agents-plugin-google';

const session = new voice.AgentSession({
   llm: new google.realtime.RealtimeModel({
      model: "gemini-2.0-flash-exp",
      modalities: [google.types.Modality.TEXT],
   }),
   tts: "cartesia/sonic-3",
});
```

## Additional resources

The following resources provide more information about using Gemini with LiveKit Agents.

![Python plugin](https://docs.livekit.io/images/sdks/python-greyscale.svg)![Python plugin](https://docs.livekit.io/images/sdks/python-greyscale.svg)

### Python plugin

[Reference](https://docs.livekit.io/reference/python/v1/livekit/plugins/google/realtime/index.html) [GitHub](https://github.com/livekit/agents/tree/main/livekit-plugins/livekit-plugins-google) [PyPI](https://pypi.org/project/livekit-plugins-google/)

![Node.js plugin](https://docs.livekit.io/images/sdks/nodejs-greyscale.svg)![Node.js plugin](https://docs.livekit.io/images/sdks/nodejs-greyscale.svg)

### Node.js plugin

[Reference](https://docs.livekit.io/reference/agents-js/modules/plugins_agents_plugin_google.html) [GitHub](https://github.com/livekit/agents-js/tree/main/plugins/google) [NPM](https://www.npmjs.com/package/@livekit/agents-plugin-google)

[**Gemini docs** \\
\\
Gemini Live API documentation.](https://ai.google.dev/gemini-api/docs/live) [**Voice AI quickstart** \\
\\
Get started with LiveKit Agents and Gemini Live API.](https://docs.livekit.io/agents/start/voice-ai/) [**Google AI ecosystem guide** \\
\\
Overview of the entire Google AI and LiveKit Agents integration.](https://docs.livekit.io/agents/integrations/google/)

On this page

[Overview](https://docs.livekit.io/agents/models/realtime/plugins/gemini/#overview) [Quick reference](https://docs.livekit.io/agents/models/realtime/plugins/gemini/#quick-reference) [Installation](https://docs.livekit.io/agents/models/realtime/plugins/gemini/#installation) [Authentication](https://docs.livekit.io/agents/models/realtime/plugins/gemini/#authentication) [Usage](https://docs.livekit.io/agents/models/realtime/plugins/gemini/#usage) [Parameters](https://docs.livekit.io/agents/models/realtime/plugins/gemini/#parameters) [Gemini tools](https://docs.livekit.io/agents/models/realtime/plugins/gemini/#gemini-tools) [Turn detection](https://docs.livekit.io/agents/models/realtime/plugins/gemini/#turn-detection) [Thinking](https://docs.livekit.io/agents/models/realtime/plugins/gemini/#thinking) [Usage with separate TTS](https://docs.livekit.io/agents/models/realtime/plugins/gemini/#separate-tts) [Additional resources](https://docs.livekit.io/agents/models/realtime/plugins/gemini/#additional-resources)

HomeAI AgentsTelephonyRecipesReference

[GitHub](https://github.com/livekit/livekit) [Slack](https://livekit.io/join-slack)

[Sign in](https://cloud.livekit.io/login?r=/login_success?redirect_to=https://docs.livekit.io/agents/models/realtime/plugins/gemini/)

Search`` `K`